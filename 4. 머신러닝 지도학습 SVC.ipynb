{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.svm.SVC\n",
    "\n",
    "*class* sklearn.svm.SVC(***, *C=1.0*, *kernel='rbf'*, *degree=3*, *gamma='scale'*, *coef0=0.0*, *shrinking=True*, *probability=False*, *tol=0.001*, *cache_size=200*, *class_weight=None*, *verbose=False*, *max_iter=- 1*, *decision_function_shape='ovr'*, *break_ties=False*, *random_state=None*)[[source]](https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/svm/_classes.py#L515)[¶](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,  x_test, y_train, y_test = train_test_split(x,y, test_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test set : [2 0 1 2 2]\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(f'y_test set : {y_test}')\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'정확도 : {accuracy_score(y_test,predictions)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[5.1 3.5 1.4 0.2]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris()\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)\n",
    "print(iris.data[0])\n",
    "print(iris.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 = setosa, label 1 = versicolor, label 2 =virginica\n",
      "Example 0 : label:0, features : [5.1 3.5 1.4 0.2]\n",
      "Example 1 : label:0, features : [4.9 3.  1.4 0.2]\n",
      "Example 2 : label:0, features : [4.7 3.2 1.3 0.2]\n",
      "Example 3 : label:0, features : [4.6 3.1 1.5 0.2]\n",
      "Example 4 : label:0, features : [5.  3.6 1.4 0.2]\n",
      "Example 5 : label:0, features : [5.4 3.9 1.7 0.4]\n",
      "Example 6 : label:0, features : [4.6 3.4 1.4 0.3]\n",
      "Example 7 : label:0, features : [5.  3.4 1.5 0.2]\n",
      "Example 8 : label:0, features : [4.4 2.9 1.4 0.2]\n",
      "Example 9 : label:0, features : [4.9 3.1 1.5 0.1]\n",
      "Example 10 : label:0, features : [5.4 3.7 1.5 0.2]\n",
      "Example 11 : label:0, features : [4.8 3.4 1.6 0.2]\n",
      "Example 12 : label:0, features : [4.8 3.  1.4 0.1]\n",
      "Example 13 : label:0, features : [4.3 3.  1.1 0.1]\n",
      "Example 14 : label:0, features : [5.8 4.  1.2 0.2]\n",
      "Example 15 : label:0, features : [5.7 4.4 1.5 0.4]\n",
      "Example 16 : label:0, features : [5.4 3.9 1.3 0.4]\n",
      "Example 17 : label:0, features : [5.1 3.5 1.4 0.3]\n",
      "Example 18 : label:0, features : [5.7 3.8 1.7 0.3]\n",
      "Example 19 : label:0, features : [5.1 3.8 1.5 0.3]\n",
      "Example 20 : label:0, features : [5.4 3.4 1.7 0.2]\n",
      "Example 21 : label:0, features : [5.1 3.7 1.5 0.4]\n",
      "Example 22 : label:0, features : [4.6 3.6 1.  0.2]\n",
      "Example 23 : label:0, features : [5.1 3.3 1.7 0.5]\n",
      "Example 24 : label:0, features : [4.8 3.4 1.9 0.2]\n",
      "Example 25 : label:0, features : [5.  3.  1.6 0.2]\n",
      "Example 26 : label:0, features : [5.  3.4 1.6 0.4]\n",
      "Example 27 : label:0, features : [5.2 3.5 1.5 0.2]\n",
      "Example 28 : label:0, features : [5.2 3.4 1.4 0.2]\n",
      "Example 29 : label:0, features : [4.7 3.2 1.6 0.2]\n",
      "Example 30 : label:0, features : [4.8 3.1 1.6 0.2]\n",
      "Example 31 : label:0, features : [5.4 3.4 1.5 0.4]\n",
      "Example 32 : label:0, features : [5.2 4.1 1.5 0.1]\n",
      "Example 33 : label:0, features : [5.5 4.2 1.4 0.2]\n",
      "Example 34 : label:0, features : [4.9 3.1 1.5 0.2]\n",
      "Example 35 : label:0, features : [5.  3.2 1.2 0.2]\n",
      "Example 36 : label:0, features : [5.5 3.5 1.3 0.2]\n",
      "Example 37 : label:0, features : [4.9 3.6 1.4 0.1]\n",
      "Example 38 : label:0, features : [4.4 3.  1.3 0.2]\n",
      "Example 39 : label:0, features : [5.1 3.4 1.5 0.2]\n",
      "Example 40 : label:0, features : [5.  3.5 1.3 0.3]\n",
      "Example 41 : label:0, features : [4.5 2.3 1.3 0.3]\n",
      "Example 42 : label:0, features : [4.4 3.2 1.3 0.2]\n",
      "Example 43 : label:0, features : [5.  3.5 1.6 0.6]\n",
      "Example 44 : label:0, features : [5.1 3.8 1.9 0.4]\n",
      "Example 45 : label:0, features : [4.8 3.  1.4 0.3]\n",
      "Example 46 : label:0, features : [5.1 3.8 1.6 0.2]\n",
      "Example 47 : label:0, features : [4.6 3.2 1.4 0.2]\n",
      "Example 48 : label:0, features : [5.3 3.7 1.5 0.2]\n",
      "Example 49 : label:0, features : [5.  3.3 1.4 0.2]\n",
      "Example 50 : label:1, features : [7.  3.2 4.7 1.4]\n",
      "Example 51 : label:1, features : [6.4 3.2 4.5 1.5]\n",
      "Example 52 : label:1, features : [6.9 3.1 4.9 1.5]\n",
      "Example 53 : label:1, features : [5.5 2.3 4.  1.3]\n",
      "Example 54 : label:1, features : [6.5 2.8 4.6 1.5]\n",
      "Example 55 : label:1, features : [5.7 2.8 4.5 1.3]\n",
      "Example 56 : label:1, features : [6.3 3.3 4.7 1.6]\n",
      "Example 57 : label:1, features : [4.9 2.4 3.3 1. ]\n",
      "Example 58 : label:1, features : [6.6 2.9 4.6 1.3]\n",
      "Example 59 : label:1, features : [5.2 2.7 3.9 1.4]\n",
      "Example 60 : label:1, features : [5.  2.  3.5 1. ]\n",
      "Example 61 : label:1, features : [5.9 3.  4.2 1.5]\n",
      "Example 62 : label:1, features : [6.  2.2 4.  1. ]\n",
      "Example 63 : label:1, features : [6.1 2.9 4.7 1.4]\n",
      "Example 64 : label:1, features : [5.6 2.9 3.6 1.3]\n",
      "Example 65 : label:1, features : [6.7 3.1 4.4 1.4]\n",
      "Example 66 : label:1, features : [5.6 3.  4.5 1.5]\n",
      "Example 67 : label:1, features : [5.8 2.7 4.1 1. ]\n",
      "Example 68 : label:1, features : [6.2 2.2 4.5 1.5]\n",
      "Example 69 : label:1, features : [5.6 2.5 3.9 1.1]\n",
      "Example 70 : label:1, features : [5.9 3.2 4.8 1.8]\n",
      "Example 71 : label:1, features : [6.1 2.8 4.  1.3]\n",
      "Example 72 : label:1, features : [6.3 2.5 4.9 1.5]\n",
      "Example 73 : label:1, features : [6.1 2.8 4.7 1.2]\n",
      "Example 74 : label:1, features : [6.4 2.9 4.3 1.3]\n",
      "Example 75 : label:1, features : [6.6 3.  4.4 1.4]\n",
      "Example 76 : label:1, features : [6.8 2.8 4.8 1.4]\n",
      "Example 77 : label:1, features : [6.7 3.  5.  1.7]\n",
      "Example 78 : label:1, features : [6.  2.9 4.5 1.5]\n",
      "Example 79 : label:1, features : [5.7 2.6 3.5 1. ]\n",
      "Example 80 : label:1, features : [5.5 2.4 3.8 1.1]\n",
      "Example 81 : label:1, features : [5.5 2.4 3.7 1. ]\n",
      "Example 82 : label:1, features : [5.8 2.7 3.9 1.2]\n",
      "Example 83 : label:1, features : [6.  2.7 5.1 1.6]\n",
      "Example 84 : label:1, features : [5.4 3.  4.5 1.5]\n",
      "Example 85 : label:1, features : [6.  3.4 4.5 1.6]\n",
      "Example 86 : label:1, features : [6.7 3.1 4.7 1.5]\n",
      "Example 87 : label:1, features : [6.3 2.3 4.4 1.3]\n",
      "Example 88 : label:1, features : [5.6 3.  4.1 1.3]\n",
      "Example 89 : label:1, features : [5.5 2.5 4.  1.3]\n",
      "Example 90 : label:1, features : [5.5 2.6 4.4 1.2]\n",
      "Example 91 : label:1, features : [6.1 3.  4.6 1.4]\n",
      "Example 92 : label:1, features : [5.8 2.6 4.  1.2]\n",
      "Example 93 : label:1, features : [5.  2.3 3.3 1. ]\n",
      "Example 94 : label:1, features : [5.6 2.7 4.2 1.3]\n",
      "Example 95 : label:1, features : [5.7 3.  4.2 1.2]\n",
      "Example 96 : label:1, features : [5.7 2.9 4.2 1.3]\n",
      "Example 97 : label:1, features : [6.2 2.9 4.3 1.3]\n",
      "Example 98 : label:1, features : [5.1 2.5 3.  1.1]\n",
      "Example 99 : label:1, features : [5.7 2.8 4.1 1.3]\n",
      "Example 100 : label:2, features : [6.3 3.3 6.  2.5]\n",
      "Example 101 : label:2, features : [5.8 2.7 5.1 1.9]\n",
      "Example 102 : label:2, features : [7.1 3.  5.9 2.1]\n",
      "Example 103 : label:2, features : [6.3 2.9 5.6 1.8]\n",
      "Example 104 : label:2, features : [6.5 3.  5.8 2.2]\n",
      "Example 105 : label:2, features : [7.6 3.  6.6 2.1]\n",
      "Example 106 : label:2, features : [4.9 2.5 4.5 1.7]\n",
      "Example 107 : label:2, features : [7.3 2.9 6.3 1.8]\n",
      "Example 108 : label:2, features : [6.7 2.5 5.8 1.8]\n",
      "Example 109 : label:2, features : [7.2 3.6 6.1 2.5]\n",
      "Example 110 : label:2, features : [6.5 3.2 5.1 2. ]\n",
      "Example 111 : label:2, features : [6.4 2.7 5.3 1.9]\n",
      "Example 112 : label:2, features : [6.8 3.  5.5 2.1]\n",
      "Example 113 : label:2, features : [5.7 2.5 5.  2. ]\n",
      "Example 114 : label:2, features : [5.8 2.8 5.1 2.4]\n",
      "Example 115 : label:2, features : [6.4 3.2 5.3 2.3]\n",
      "Example 116 : label:2, features : [6.5 3.  5.5 1.8]\n",
      "Example 117 : label:2, features : [7.7 3.8 6.7 2.2]\n",
      "Example 118 : label:2, features : [7.7 2.6 6.9 2.3]\n",
      "Example 119 : label:2, features : [6.  2.2 5.  1.5]\n",
      "Example 120 : label:2, features : [6.9 3.2 5.7 2.3]\n",
      "Example 121 : label:2, features : [5.6 2.8 4.9 2. ]\n",
      "Example 122 : label:2, features : [7.7 2.8 6.7 2. ]\n",
      "Example 123 : label:2, features : [6.3 2.7 4.9 1.8]\n",
      "Example 124 : label:2, features : [6.7 3.3 5.7 2.1]\n",
      "Example 125 : label:2, features : [7.2 3.2 6.  1.8]\n",
      "Example 126 : label:2, features : [6.2 2.8 4.8 1.8]\n",
      "Example 127 : label:2, features : [6.1 3.  4.9 1.8]\n",
      "Example 128 : label:2, features : [6.4 2.8 5.6 2.1]\n",
      "Example 129 : label:2, features : [7.2 3.  5.8 1.6]\n",
      "Example 130 : label:2, features : [7.4 2.8 6.1 1.9]\n",
      "Example 131 : label:2, features : [7.9 3.8 6.4 2. ]\n",
      "Example 132 : label:2, features : [6.4 2.8 5.6 2.2]\n",
      "Example 133 : label:2, features : [6.3 2.8 5.1 1.5]\n",
      "Example 134 : label:2, features : [6.1 2.6 5.6 1.4]\n",
      "Example 135 : label:2, features : [7.7 3.  6.1 2.3]\n",
      "Example 136 : label:2, features : [6.3 3.4 5.6 2.4]\n",
      "Example 137 : label:2, features : [6.4 3.1 5.5 1.8]\n",
      "Example 138 : label:2, features : [6.  3.  4.8 1.8]\n",
      "Example 139 : label:2, features : [6.9 3.1 5.4 2.1]\n",
      "Example 140 : label:2, features : [6.7 3.1 5.6 2.4]\n",
      "Example 141 : label:2, features : [6.9 3.1 5.1 2.3]\n",
      "Example 142 : label:2, features : [5.8 2.7 5.1 1.9]\n",
      "Example 143 : label:2, features : [6.8 3.2 5.9 2.3]\n",
      "Example 144 : label:2, features : [6.7 3.3 5.7 2.5]\n",
      "Example 145 : label:2, features : [6.7 3.  5.2 2.3]\n",
      "Example 146 : label:2, features : [6.3 2.5 5.  1.9]\n",
      "Example 147 : label:2, features : [6.5 3.  5.2 2. ]\n",
      "Example 148 : label:2, features : [6.2 3.4 5.4 2.3]\n",
      "Example 149 : label:2, features : [5.9 3.  5.1 1.8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris()\n",
    "\n",
    "print(f'label 0 = setosa, label 1 = versicolor, label 2 =virginica')\n",
    "for i in range(len(iris.target)):\n",
    "    print(f\"Example {i} : label:{iris.target[i]}, features : {iris.data[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20fe8547970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "iris = load_iris()\n",
    "sepal = iris.data[:,0:2]\n",
    "kind = iris.target \n",
    "\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.plot (sepal[kind == 0][:,0], sepal[kind ==0][:,1],\"ro\",label='Setosa')\n",
    "plt.plot (sepal[kind == 1][:,0], sepal[kind ==1][:,1],\"bo\",label='Versicolor')\n",
    "plt.plot (sepal[kind == 2][:,0], sepal[kind ==2][:,1],\"yo\",label='Virginica')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris  \n",
    "iris = load_iris()\n",
    "#print(iris.data)\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# (80:20)으로 분할한다.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)  \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "scores = metrics.accuracy_score(y_test, y_pred)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "knn.fit(X, y)\n",
    "\n",
    "#0 = setosa, 1=versicolor, 2=virginica\n",
    "classes = {0:'setosa',1:'versicolor',2:'virginica'}\n",
    "\n",
    "# 아직 보지 못한 새로운 데이터를 제시해보자.  \n",
    "x_new = [[3,4,5,2],[5,4,2,2]]\n",
    "y_predict = knn.predict(x_new)\n",
    "\n",
    "print(classes[y_predict[0]])  \n",
    "print(classes[y_predict[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression,make_classification\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#make classification이라는 데이터를 하나 만듦\n",
    "X, y = make_classification(n_samples=100,n_features=10,n_informative=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# it takes a list of tuples as parameter\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "# use the pipeline object as you would\n",
    "# a regular classifier\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression,make_classification\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#make classification이라는 데이터를 하나 만듦\n",
    "# 함수 만들어서 넣어도 상관없다 \n",
    "X, y = make_classification(n_samples=100,n_features=10,n_informative=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# it takes a list of tuples as parameter\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "# use the pipeline object as you would\n",
    "# a regular classifier\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉할때 드랍시켜서 \n",
    "숫자로 라벨인코더 했다. \n",
    "그리고 3가지를 나열한 다음에 \n",
    "파이프로 연결시켜보자 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "\n",
    "def encode_features(dataDF):\n",
    "  features = ['Cabin', 'Sex', 'Embarked']\n",
    "  for feature in features:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le = le.fit(dataDF[feature])\n",
    "    dataDF[feature] = le.transform(dataDF[feature])\n",
    "    \n",
    "  return dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\Day5_SVC.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=20'>21</a>\u001b[0m X_train\u001b[39m.\u001b[39mshape, X_test\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=21'>22</a>\u001b[0m \u001b[39m#차원을 이야기하는건데 140,3이면 140개의 3개가 있다는건데 한 피쳐당 140개가 있다는 거고. \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=22'>23</a>\u001b[0m \u001b[39m# 5,6,4 이면 5행 4행렬이 3개니까 3차원 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=23'>24</a>\u001b[0m \u001b[39m# 5,4,100 이면 3차원 \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=28'>29</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=29'>30</a>\u001b[0m \u001b[39m# it takes a list of tuples as parameter\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=30'>31</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=31'>32</a>\u001b[0m     (\u001b[39m'\u001b[39;49m\u001b[39mencode\u001b[39;49m\u001b[39m'\u001b[39;49m,encode_features(titanic_df)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=32'>33</a>\u001b[0m     (\u001b[39m'\u001b[39;49m\u001b[39mclf\u001b[39;49m\u001b[39m'\u001b[39;49m, LogisticRegression())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=33'>34</a>\u001b[0m \t])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=35'>36</a>\u001b[0m \u001b[39m# use the pipeline object as you would\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=36'>37</a>\u001b[0m \u001b[39m# a regular classifier\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/Day5_SVC.ipynb#ch0000016?line=37'>38</a>\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X_train,y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:148\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=145'>146</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39m=\u001b[39m memory\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=146'>147</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m verbose\n\u001b[1;32m--> <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=147'>148</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:202\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=198'>199</a>\u001b[0m estimator \u001b[39m=\u001b[39m estimators[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=200'>201</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m transformers:\n\u001b[1;32m--> <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=201'>202</a>\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m t \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mpassthrough\u001b[39;49m\u001b[39m\"\u001b[39;49m:\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=202'>203</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=203'>204</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=204'>205</a>\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/pipeline.py?line=205'>206</a>\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:1535\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1532'>1533</a>\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1533'>1534</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1534'>1535</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1535'>1536</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1536'>1537</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/JIHYUN/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1537'>1538</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression,make_classification\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "#make classification이라는 데이터를 하나 만듦\n",
    "# 함수 만들어서 넣어도 상관없다 \n",
    "# X, y = make_classification(n_samples=100,n_features=10,n_informative=2)\n",
    "\n",
    "titanic_df = pd.read_csv('./dataset/titanic_train.csv')\n",
    "\n",
    "y_titanic_df = titanic_df['Survived'] #레이블 값 만들어 Y값 데이터로 저장 \n",
    "x_titanic_df = titanic_df.drop(['Survived'],axis=1) #레이블값을 제외한 인풋값 저장 \n",
    "x_train,x_test,y_train,y_test = train_test_split(x_titanic_df,y_titanic_df, test_size=0.2,random_state= 42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "#차원을 이야기하는건데 140,3이면 140개의 3개가 있다는건데 한 피쳐당 140개가 있다는 거고. \n",
    "# 5,6,4 이면 5행 4행렬이 3개니까 3차원 \n",
    "# 5,4,100 이면 3차원 \n",
    "# 그래서 갯수 세보려고 확인해보려고 찍는 것 이게 몇차원행렬인지 \n",
    "# 140\n",
    "#벡터는 어레이로 연산해야한다. 리스트로 연산하면 안된다. \n",
    "\n",
    "\n",
    "# it takes a list of tuples as parameter\n",
    "pipeline = Pipeline([\n",
    "    ('encode',encode_features(titanic_df)),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "# use the pipeline object as you would\n",
    "# a regular classifier\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#판다스 데이터 프레임 파이프라인으로 전처리 하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d9aeff0c4cb62f006bcee5d924029c89375552da6e18543b57335e832e7bb6d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
